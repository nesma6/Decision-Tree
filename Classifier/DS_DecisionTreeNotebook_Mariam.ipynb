{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from graphviz import Digraph\n",
    "from graphviz import Graph\n",
    "# import pydot\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainData = pd.read_csv('../Datasets/sample_train.csv')\n",
    "# devData = pd.read_csv('../Datasets/sample_dev.csv')\n",
    "# testData = pd.read_csv('../Datasets/sample_test.csv')\n",
    "# dataFrame = pd.DataFrame(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_init(file):\n",
    "    trainData = pd.read_csv(file)\n",
    "    dataFrame = pd.DataFrame(trainData)\n",
    "    return dataFrame\n",
    "#     dataFrame=dataFrame.drop(\"rating\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_count(dataFrame):\n",
    "    d = []\n",
    "    if 'rating' in dataFrame.columns:\n",
    "        d = dataFrame.rating\n",
    "        dataFrame = dataFrame.drop('rating',axis=1)\n",
    "    features = ['contains_No', 'contains_Please', 'contains_Thank', 'contains_apologize', 'contains_bad',\n",
    "    'contains_clean', 'contains_comfortable', 'contains_dirty', 'contains_enjoyed', 'contains_friendly',\n",
    "    'contains_glad', 'contains_good', 'contains_great', 'contains_happy', 'contains_hot', 'contains_issues',\n",
    "    'contains_nice', 'contains_noise', 'contains_old', 'contains_poor', 'contains_right', 'contains_small', \n",
    "    'contains_smell', 'contains_sorry', 'contains_wonderful', 'reviews.text', 'count_reviews.text']\n",
    "    \n",
    "    for i in dataFrame.columns:\n",
    "        c = i.replace('contains_','')\n",
    "        col = []\n",
    "        for j in range(0,dataFrame.shape[0]):\n",
    "            if dataFrame[i][j]==1:\n",
    "                col.append(dataFrame['reviews.text'][j].count(c))\n",
    "            else:\n",
    "                col.append(0)\n",
    "        dataFrame['count_'+c]=col\n",
    "    \n",
    "    dataFrame = dataFrame.drop(features,axis=1)\n",
    "    dataFrame = dataFrame.join(d)\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_purity(data):\n",
    "    \n",
    "    rating_column = data[:, -1]\n",
    "    unique_classes = np.unique(rating_column)\n",
    "\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(data):\n",
    "    \n",
    "    rating_column = data[:, -1]\n",
    "    unique_classes, counts_unique_classes = np.unique(rating_column, return_counts=True)\n",
    "\n",
    "    index = counts_unique_classes.argmax()\n",
    "    classification = unique_classes[index]\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(data):\n",
    "    \n",
    "    potential_splits = {}\n",
    "    n_columns = data.shape[1]\n",
    "    for column_index in range(n_columns - 1):        # excluding the last column which is the rating\n",
    "        potential_splits[column_index] = []\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "\n",
    "        potential_splits[column_index]=unique_values\n",
    "        \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, split_column, split_value):\n",
    "    \n",
    "    split_column_values = data[:, split_column]\n",
    "\n",
    "    data_below = data[split_column_values <= split_value]\n",
    "    data_above = data[split_column_values > split_value]\n",
    "    \n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(data):\n",
    "    \n",
    "    rating_column = data[:, -1]\n",
    "    _, counts = np.unique(rating_column, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "     \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_entropy(data_below, data_above):\n",
    "    \n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "\n",
    "    overall_entropy =  (p_data_below * calculate_entropy(data_below) \n",
    "                      + p_data_above * calculate_entropy(data_above))\n",
    "    \n",
    "    return overall_entropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split(data, potential_splits):\n",
    "    \n",
    "    overall_entropy = 9999\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
    "            current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
    "\n",
    "            if current_overall_entropy <= overall_entropy:\n",
    "                overall_entropy = current_overall_entropy\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df, counter=0, min_samples=2, max_depth=5):\n",
    "    \n",
    "    # data preparations\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df           \n",
    "    \n",
    "    \n",
    "    # base cases\n",
    "    if (check_purity(data)) or (len(data) < min_samples) or (counter == max_depth):\n",
    "        classification = classify_data(data)\n",
    "        \n",
    "        return classification\n",
    "\n",
    "    \n",
    "    # recursive part\n",
    "    else:    \n",
    "        counter += 1\n",
    "\n",
    "        # helper functions \n",
    "        potential_splits = get_potential_splits(data)\n",
    "        split_column, split_value = determine_best_split(data, potential_splits)\n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "        \n",
    "        if len(data_below)==0 or len(data_above)==0:    \n",
    "            classification = classify_data(data)\n",
    "            return classification\n",
    "            \n",
    "        \n",
    "        # instantiate sub-tree --to be converted into nodes\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        question = \"{} = {}\".format(feature_name, split_value)\n",
    "        sub_tree = {question: []}\n",
    "    \n",
    "        yes_answer = decision_tree_algorithm(data_below, counter, min_samples, max_depth)\n",
    "        no_answer = decision_tree_algorithm(data_above, counter, min_samples, max_depth)\n",
    "\n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "            \n",
    "        \n",
    "        \n",
    "        return sub_tree\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_example(example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split()\n",
    "\n",
    "    # ask question\n",
    "    if str(example[feature_name]) <= value:\n",
    "        \n",
    "        answer = tree[question][0]\n",
    "    else:\n",
    "        answer = tree[question][1]\n",
    "\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return classify_example(example, residual_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df,tree):\n",
    "    df=words_count(df)\n",
    "    df[\"classification\"] = df.apply(classify_example, axis=1, args=(tree,))\n",
    "    with open('output.txt', 'w') as f:\n",
    "        for text in df['classification'].tolist():\n",
    "            f.write(text + '\\n')\n",
    "    return df['classification'].values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(df_, tree,show=False):\n",
    "    df=words_count(df_)\n",
    "    df[\"classification\"] = df.apply(classify_example, axis=1, args=(tree,))\n",
    "    df[\"classification_correct\"] = df[\"classification\"] == df[\"rating\"]\n",
    "    \n",
    "    accuracy = df[\"classification_correct\"].mean()\n",
    "    if show==True:\n",
    "        print(df[['classification', 'classification_correct']])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Node and Tree Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,key):\n",
    "        self.val = key\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "    def set_val(self,_val):\n",
    "        self.val=_val\n",
    "    def get_val(self):\n",
    "        return self.val\n",
    "    def set_left(self,_left):\n",
    "        self.left=_left\n",
    "    def get_left(self):\n",
    "        return self.left\n",
    "    def set_right(self,_right):\n",
    "        self.right=_right\n",
    "    def get_right(self):\n",
    "        return self.right\n",
    "    \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__(self, _val = None):\n",
    "        self.root = Node(_val)\n",
    "        self.right, self.left = None, None\n",
    "    def insert_right(self,right_node):\n",
    "        if not isinstance(right_node, Tree):\n",
    "            self.root.right=right_node\n",
    "        else:\n",
    "            self.root.right=right_node.root\n",
    "            \n",
    "    def insert_left(self,left_node):\n",
    "        if not isinstance(left_node, Tree):\n",
    "            self.root.left=left_node\n",
    "        else:\n",
    "            self.root.left=left_node.root     \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing the trained tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(tree):\n",
    "    global d\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name,_,value = question.split()\n",
    "    d.node(feature_name+value,question)\n",
    "    \n",
    "    answer_yes  = tree[question][0]\n",
    "   \n",
    "    answer_no = tree[question][1]\n",
    "    \n",
    "    if not isinstance(answer_yes, dict):\n",
    "        d.node(feature_name+value+answer_yes,answer_yes)\n",
    "        d.edge(feature_name+value,feature_name+value+answer_yes)\n",
    "    else:\n",
    "        answer_question_yes = list(answer_yes.keys())[0]\n",
    "        feature_name_yes,_,value_yes = answer_question_yes.split()\n",
    "        d.node(feature_name_yes+value_yes,feature_name_yes)\n",
    "        d.edge(feature_name+value,feature_name_yes+value_yes)\n",
    "        draw_graph(answer_yes)\n",
    "   \n",
    "    if not isinstance(answer_no, dict):\n",
    "        d.node(feature_name+value+answer_no,answer_no)\n",
    "        d.edge(feature_name+value,feature_name+value+answer_no)\n",
    "    else:\n",
    "        answer_question_no = list(answer_no.keys())[0]\n",
    "        feature_name_no,_,value_no = answer_question_no.split()\n",
    "        d.node(feature_name_no+value_no,feature_name_no)\n",
    "        d.edge(feature_name+value,feature_name_no+value_no)\n",
    "        draw_graph(answer_no)\n",
    "    return\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    #answer_yes  = list(tree[question][0].keys())[0]\n",
    "    #answer_node = list(tree[question][1].keys())[0]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph2(tree,count=0):\n",
    "    global d\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name,_,value = question.split()\n",
    "    d.node(feature_name+str(count),question)\n",
    "    \n",
    "    answer_yes  = tree[question][0]\n",
    "   \n",
    "    answer_no = tree[question][1]\n",
    "    \n",
    "    if not isinstance(answer_yes, dict):\n",
    "        d.node(feature_name+str(count)+answer_yes,answer_yes)\n",
    "        d.edge(feature_name+str(count),feature_name+str(count)+answer_yes)\n",
    "    else:\n",
    "        answer_question_yes = list(answer_yes.keys())[0]\n",
    "        feature_name_yes,_,_ = answer_question_yes.split()\n",
    "        d.node(feature_name_yes+str(count),answer_question_yes)\n",
    "        d.edge(feature_name+str(count),feature_name_yes+str(count))\n",
    "        draw_graph2(answer_yes,count+1)\n",
    "   \n",
    "    if not isinstance(answer_no, dict):\n",
    "        d.node(feature_name+str(count)+answer_no,answer_no)\n",
    "        d.edge(feature_name+str(count),feature_name+str(count)+answer_no)\n",
    "    else:\n",
    "        answer_question_no = list(answer_no.keys())[0]\n",
    "        feature_name_no,_,_ = answer_question_no.split()\n",
    "        d.node(feature_name_no+str(count),answer_question_no)\n",
    "        d.edge(feature_name+str(count),feature_name_no+str(count))\n",
    "        draw_graph2(answer_no,count+1)\n",
    "    return\n",
    "        \n",
    "            \n",
    "    \n",
    "    #answer_yes  = list(tree[question][0].keys())[0]\n",
    "    #answer_node = list(tree[question][1].keys())[0]\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
